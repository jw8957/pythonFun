{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing 101\n",
    "\n",
    "Simple examples of image processing concepts on OpenCV. Concepts explored:\n",
    "\n",
    "* Data structures\n",
    "* Color and color conversions\n",
    "* Thresholding and masking\n",
    "* Blurring\n",
    "* Contours and bounding rectangles\n",
    "* Edges\n",
    "* Hough Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data structures in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read an image\n",
    "img = cv2.imread('images/noguchi02.jpg')\n",
    "\n",
    "# show image format (basically a 3-d array of pixel color info, in BGR format)\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors and color conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert image to RGB color for matplotlib\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# show image with matplotlib\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# grayscale image represented as a 2-d array\n",
    "print(gray_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to convert grayscale back to RGB for plt.imshow()\n",
    "plt.imshow(cv2.cvtColor(gray_img, cv2.COLOR_GRAY2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the average color of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find average per row\n",
    "# np.average() takes in an axis argument which finds the average across that axis. \n",
    "average_color_per_row = np.average(img, axis=0)\n",
    "\n",
    "# find average across average per row\n",
    "average_color = np.average(average_color_per_row, axis=0)\n",
    "\n",
    "# convert back to uint8\n",
    "average_color = np.uint8(average_color)\n",
    "print(average_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 100 x 100 pixel array with average color value\n",
    "average_color_img = np.array([[average_color]*100]*100, np.uint8)\n",
    "\n",
    "plt.imshow(average_color_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Binary thresholding\n",
    "\n",
    "Examples using thresholding on brightness/darkness of grayscale image and on color ranges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary thresholding on grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold for grayscale image\n",
    "_, threshold_img = cv2.threshold(gray_img, 60, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "threshold_img = cv2.cvtColor(threshold_img, cv2.COLOR_GRAY2RGB)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(threshold_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary thresholding on color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open new Mondrian Piet painting photo\n",
    "piet = cv2.imread('images/piet.png')\n",
    "piet_hsv = cv2.cvtColor(piet, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(piet, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold for hue channel in blue range\n",
    "blue_min = np.array([85, 60, 60], np.uint8)\n",
    "blue_max = np.array([150, 255, 255], np.uint8)\n",
    "threshold_blue_img = cv2.inRange(piet_hsv, blue_min, blue_max)\n",
    "\n",
    "# show threshold bits\n",
    "threshold_blue_img = cv2.cvtColor(threshold_blue_img, cv2.COLOR_GRAY2RGB)\n",
    "plt.imshow(threshold_blue_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using binary thresholding to obtain an image mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstate = cv2.imread('images/upstate-ny.jpg')\n",
    "upstate_hsv = cv2.cvtColor(upstate, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(upstate_hsv, cv2.COLOR_HSV2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_inverse = cv2.inRange(upstate_hsv, blue_min, blue_max)\n",
    "mask = cv2.bitwise_not(mask_inverse)\n",
    "plt.imshow(cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert single channel mask back into 3 channels\n",
    "mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# perform bitwise and on mask to obtain cut-out image that is not blue\n",
    "masked_upstate = cv2.bitwise_and(upstate, mask_rgb)\n",
    "\n",
    "# replace the cut-out parts with white\n",
    "masked_replace_white = cv2.addWeighted(masked_upstate, 1, \\\n",
    "                                       cv2.cvtColor(mask_inverse, cv2.COLOR_GRAY2RGB), 1, 0)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(masked_replace_white, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Gaussian Blur\n",
    "\n",
    "Gaussian blurring in action, and how it makes a difference in the binary image that it produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/oy.jpg')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preproccess with blurring, with 5x5 kernel\n",
    "img_blur_small = cv2.GaussianBlur(img, (5,5), 0)\n",
    "cv2.imwrite('output/oy-gaussian-blur-5.jpg', img_blur_small)\n",
    "plt.imshow(cv2.cvtColor(img_blur_small, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_blur_small = cv2.GaussianBlur(img, (5,5), 25)\n",
    "cv2.imwrite('output/oy-gaussian-blur-5-3.jpg', img_blur_small)\n",
    "plt.imshow(cv2.cvtColor(img_blur_small, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_blur_large = cv2.GaussianBlur(img, (15,15), 0)\n",
    "cv2.imwrite('output/oy-gaussian-blur-15.jpg', img_blur_large)\n",
    "plt.imshow(cv2.cvtColor(img_blur_large, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold on regular image\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "_, threshold_img = cv2.threshold(gray_img, 100, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('output/oy-no-blur-thresh.jpg', threshold_img)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(threshold_img, cv2.COLOR_GRAY2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold on blurred image\n",
    "gray_blur_img = cv2.cvtColor(img_blur_small, cv2.COLOR_BGR2GRAY)\n",
    "_, threshold_img_blur = cv2.threshold(gray_blur_img, 100, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('output/oy-gaussian-blur-5-thresh.jpg', threshold_img_blur)\n",
    "plt.imshow(cv2.cvtColor(threshold_img_blur, cv2.COLOR_GRAY2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using adaptive threshold instead of global\n",
    "adaptive_thresh = cv2.adaptiveThreshold(gray_img,255,\\\n",
    "                                         cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                                         cv2.THRESH_BINARY,11,2)\n",
    "plt.imshow(cv2.cvtColor(adaptive_thresh, cv2.COLOR_GRAY2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Contour and bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = cv2.imread('images/coins.jpg')\n",
    "plt.imshow(cv2.cvtColor(coins, cv2.COLOR_BGR2RGB))\n",
    "cv2.imwrite('output/coins-orig.jpg', coins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get binary image and apply Gaussian blur\n",
    "coins_gray = cv2.cvtColor(coins, cv2.COLOR_BGR2GRAY)\n",
    "coins_preprocessed = cv2.GaussianBlur(coins_gray, (5, 5), 0)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(coins_preprocessed, cv2.COLOR_GRAY2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, coins_binary = cv2.threshold(coins_preprocessed, 130, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# invert image to get coins\n",
    "coins_binary = cv2.bitwise_not(coins_binary)\n",
    "plt.imshow(cv2.cvtColor(coins_binary, cv2.COLOR_GRAY2RGB))\n",
    "cv2.imwrite('output/coins-binary.png', coins_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morph coins by eroding and dilating to remove noise\n",
    "morph_kernel = np.ones((15,15),np.uint8)\n",
    "coins_morph = cv2.morphologyEx(coins_binary, cv2.MORPH_CLOSE, morph_kernel)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(coins_morph, cv2.COLOR_GRAY2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Get countours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours\n",
    "coins_contours, _ = cv2.findContours(coins_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# make copy of image\n",
    "coins_and_contours = np.copy(coins)\n",
    "\n",
    "# find contours of large enough area\n",
    "min_coin_area = 60\n",
    "large_contours = [cnt for cnt in coins_contours if cv2.contourArea(cnt) > min_coin_area]\n",
    "\n",
    "# draw contours\n",
    "cv2.drawContours(coins_and_contours, large_contours, -1, (255,0,0))\n",
    "\n",
    "plt.imshow(cv2.cvtColor(coins_and_contours, cv2.COLOR_BGR2RGB))\n",
    "cv2.imwrite('output/coins-contour.jpg', coins_and_contours)\n",
    "\n",
    "# print number of contours\n",
    "print('number of coins: %d' % len(large_contours))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create copy of image to draw bounding boxes\n",
    "bounding_img = np.copy(coins)\n",
    "\n",
    "# for each contour find bounding box and draw rectangle\n",
    "for contour in large_contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    cv2.rectangle(bounding_img, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(bounding_img, cv2.COLOR_BGR2RGB))\n",
    "cv2.imwrite('output/coins-bounding.jpg', bounding_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge detection\n",
    "Canny edge detector on OpenCV. Usage of edge detection versus thresholding to obtain binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cups = cv2.imread('images/cups.jpg')\n",
    "plt.imshow(cv2.cvtColor(cups, cv2.COLOR_BGR2RGB))\n",
    "cv2.imwrite('output/cups-orig.jpg', cups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess by blurring and grayscale\n",
    "cups_preprocessed  = cv2.cvtColor(cv2.GaussianBlur(cups, (7,7), 0), cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find binary image with thresholding\n",
    "low_thresh = 120\n",
    "high_thresh = 200\n",
    "_, cups_thresh = cv2.threshold(cups_preprocessed, low_thresh, 255, cv2.THRESH_BINARY)\n",
    "plt.imshow(cv2.cvtColor(cups_thresh, cv2.COLOR_GRAY2RGB))\n",
    "cv2.imwrite('output/cups-thresh-low.png', cups_thresh)\n",
    "\n",
    "_, cups_thresh_hi = cv2.threshold(cups_preprocessed, high_thresh, 255, cv2.THRESH_BINARY)\n",
    "cv2.imwrite('output/cups-thresh-hi.png', cups_thresh_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find binary image with edges\n",
    "cups_edges = cv2.Canny(cups_preprocessed, threshold1=90, threshold2=110)\n",
    "plt.imshow(cv2.cvtColor(cups_edges, cv2.COLOR_GRAY2RGB))\n",
    "cv2.imwrite('output/cups-edges.png', cups_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hough Transform \n",
    "\n",
    "Example of using cv2.HoughCircles and cv2.HoughLines to detect circles and lines on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find hough circles\n",
    "circles = cv2.HoughCircles(cups_edges, cv2.cv.CV_HOUGH_GRADIENT, dp=1.5, minDist=50, minRadius=20, maxRadius=130)\n",
    "cups_circles = np.copy(cups)\n",
    "\n",
    "# if circles are detected, draw them\n",
    "if circles is not None and len(circles) > 0:\n",
    "    for (x, y, r) in circles[0]:\n",
    "        x, y, r = int(x), int(y), int(r)\n",
    "        cv2.circle(cups_circles, (x, y), r, (255, 255, 0), 4)\n",
    "    plt.imshow(cv2.cvtColor(cups_circles, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "print('number of circles detected: %d' % len(circles[0]))\n",
    "cv2.imwrite('output/cups-circles.jpg', cups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line detection\n",
    "\n",
    "# copy of image to draw lines\n",
    "cups_lines = np.copy(cups)\n",
    "\n",
    "# find hough lines\n",
    "num_pix_threshold = 110 # minimum number of pixels that must be on a line\n",
    "lines = cv2.HoughLines(cups_edges, 1, np.pi/180, num_pix_threshold)\n",
    "\n",
    "for rho, theta in lines[0]:\n",
    "    # convert line equation into start and end points of line\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho \n",
    "    y0 = b * rho \n",
    "\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "\n",
    "    cv2.line(cups_lines, (x1,y1), (x2,y2), (255,0,255), 2)\n",
    "plt.imshow(cv2.cvtColor(cups_lines, cv2.COLOR_BGR2RGB))\n",
    "cv2.imwrite('output/cups-lines.jpg', cups_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The end!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
